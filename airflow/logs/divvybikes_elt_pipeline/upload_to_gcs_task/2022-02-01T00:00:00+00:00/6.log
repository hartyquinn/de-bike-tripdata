[2022-04-06 18:46:29,941] {taskinstance.py:903} INFO - Dependencies all met for <TaskInstance: divvybikes_elt_pipeline.upload_to_gcs_task 2022-02-01T00:00:00+00:00 [None]>
[2022-04-06 18:46:29,950] {taskinstance.py:903} INFO - Dependencies all met for <TaskInstance: divvybikes_elt_pipeline.upload_to_gcs_task 2022-02-01T00:00:00+00:00 [None]>
[2022-04-06 18:46:29,950] {taskinstance.py:1094} INFO - 
--------------------------------------------------------------------------------
[2022-04-06 18:46:29,950] {taskinstance.py:1095} INFO - Starting attempt 6 of 7
[2022-04-06 18:46:29,951] {taskinstance.py:1096} INFO - 
--------------------------------------------------------------------------------
[2022-04-06 18:46:29,962] {taskinstance.py:1114} INFO - Executing <Task(PythonOperator): upload_to_gcs_task> on 2022-02-01T00:00:00+00:00
[2022-04-06 18:46:29,966] {standard_task_runner.py:52} INFO - Started process 1645 to run task
[2022-04-06 18:46:29,970] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'divvybikes_elt_pipeline', 'upload_to_gcs_task', '2022-02-01T00:00:00+00:00', '--job-id', '239', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/extract_load.py', '--cfg-path', '/tmp/tmpt6kmosyi', '--error-file', '/tmp/tmp315w3juz']
[2022-04-06 18:46:29,972] {standard_task_runner.py:77} INFO - Job 239: Subtask upload_to_gcs_task
[2022-04-06 18:46:30,004] {logging_mixin.py:109} INFO - Running <TaskInstance: divvybikes_elt_pipeline.upload_to_gcs_task 2022-02-01T00:00:00+00:00 [running]> on host 0489e83a67f4
[2022-04-06 18:46:30,041] {taskinstance.py:1253} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=divvybikes_elt_pipeline
AIRFLOW_CTX_TASK_ID=upload_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-02-01T00:00:00+00:00
[2022-04-06 18:46:30,490] {taskinstance.py:1462} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2593, in upload_from_file
    retry=retry,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2411, in _do_upload
    retry=retry,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2236, in _do_resumable_upload
    retry=retry,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2111, in _initiate_resumable_upload
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/resumable_media/requests/upload.py", line 413, in initiate
    self._process_initiate_response(response)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/resumable_media/_upload.py", line 506, in _process_initiate_response
    callback=self._make_invalid,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/resumable_media/_helpers.py", line 104, in require_status_code
    *status_codes
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1164, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1282, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1312, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 150, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 161, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/extract_load.py", line 77, in upload_to_gcs
    blob.upload_from_filename(local_file)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2734, in upload_from_filename
    retry=retry,
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 2597, in upload_from_file
    _raise_from_invalid_response(exc)
  File "/home/airflow/.local/lib/python3.6/site-packages/google/cloud/storage/blob.py", line 4363, in _raise_from_invalid_response
    raise exceptions.from_http_status(response.status_code, message, response=response)
google.api_core.exceptions.Forbidden: 403 POST https://storage.googleapis.com/upload/storage/v1/b/dtc_data_lake_pivotal-surfer-336713/o?uploadType=resumable: {
  "error": {
    "code": 403,
    "message": "The billing account for the owning project is disabled in state closed",
    "errors": [
      {
        "message": "The billing account for the owning project is disabled in state closed",
        "domain": "global",
        "reason": "accountDisabled",
        "locationType": "header",
        "location": "Authorization"
      }
    ]
  }
}
: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)
[2022-04-06 18:46:30,492] {taskinstance.py:1512} INFO - Marking task as UP_FOR_RETRY. dag_id=divvybikes_elt_pipeline, task_id=upload_to_gcs_task, execution_date=20220201T000000, start_date=20220406T184629, end_date=20220406T184630
[2022-04-06 18:46:30,546] {local_task_job.py:151} INFO - Task exited with return code 1
[2022-04-06 18:46:30,565] {local_task_job.py:261} INFO - 0 downstream tasks scheduled from follow-on schedule check
