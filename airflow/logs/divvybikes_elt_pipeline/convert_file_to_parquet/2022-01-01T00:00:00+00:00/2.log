[2022-04-07 00:57:30,278] {taskinstance.py:903} INFO - Dependencies all met for <TaskInstance: divvybikes_elt_pipeline.convert_file_to_parquet 2022-01-01T00:00:00+00:00 [None]>
[2022-04-07 00:57:30,287] {taskinstance.py:903} INFO - Dependencies all met for <TaskInstance: divvybikes_elt_pipeline.convert_file_to_parquet 2022-01-01T00:00:00+00:00 [None]>
[2022-04-07 00:57:30,287] {taskinstance.py:1094} INFO - 
--------------------------------------------------------------------------------
[2022-04-07 00:57:30,287] {taskinstance.py:1095} INFO - Starting attempt 2 of 3
[2022-04-07 00:57:30,288] {taskinstance.py:1096} INFO - 
--------------------------------------------------------------------------------
[2022-04-07 00:57:30,298] {taskinstance.py:1114} INFO - Executing <Task(PythonOperator): convert_file_to_parquet> on 2022-01-01T00:00:00+00:00
[2022-04-07 00:57:30,302] {standard_task_runner.py:52} INFO - Started process 1572 to run task
[2022-04-07 00:57:30,305] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'divvybikes_elt_pipeline', 'convert_file_to_parquet', '2022-01-01T00:00:00+00:00', '--job-id', '254', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/extract_load.py', '--cfg-path', '/tmp/tmp0il1exla', '--error-file', '/tmp/tmpr52yu8w3']
[2022-04-07 00:57:30,306] {standard_task_runner.py:77} INFO - Job 254: Subtask convert_file_to_parquet
[2022-04-07 00:57:30,341] {logging_mixin.py:109} INFO - Running <TaskInstance: divvybikes_elt_pipeline.convert_file_to_parquet 2022-01-01T00:00:00+00:00 [running]> on host afa4c4c5de3b
[2022-04-07 00:57:30,380] {taskinstance.py:1253} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=divvybikes_elt_pipeline
AIRFLOW_CTX_TASK_ID=convert_file_to_parquet
AIRFLOW_CTX_EXECUTION_DATE=2022-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-01-01T00:00:00+00:00
[2022-04-07 00:57:30,537] {python.py:151} INFO - Done. Returned value was: None
[2022-04-07 00:57:30,546] {taskinstance.py:1218} INFO - Marking task as SUCCESS. dag_id=divvybikes_elt_pipeline, task_id=convert_file_to_parquet, execution_date=20220101T000000, start_date=20220407T005730, end_date=20220407T005730
[2022-04-07 00:57:30,598] {local_task_job.py:151} INFO - Task exited with return code 0
[2022-04-07 00:57:30,616] {local_task_job.py:261} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-04-07 00:57:30,629] {dagrun.py:486} WARNING - Failed to get task '<TaskInstance: divvybikes_elt_pipeline.create_s3_connection 2022-01-01 00:00:00+00:00 [removed]>' for dag 'divvybikes_elt_pipeline'. Marking it as removed.
[2022-04-07 00:57:30,631] {dagrun.py:486} WARNING - Failed to get task '<TaskInstance: divvybikes_elt_pipeline.upload_file_to_s3 2022-01-01 00:00:00+00:00 [removed]>' for dag 'divvybikes_elt_pipeline'. Marking it as removed.
[2022-04-07 00:57:30,634] {dagrun.py:449} ERROR - Deadlock; marking run <DagRun divvybikes_elt_pipeline @ 2022-01-01 00:00:00+00:00: backfill__2022-01-01T00:00:00+00:00, externally triggered: False> failed
[2022-04-07 00:57:30,636] {dagrun.py:604} WARNING - Failed to record duration of <DagRun divvybikes_elt_pipeline @ 2022-01-01 00:00:00+00:00: backfill__2022-01-01T00:00:00+00:00, externally triggered: False>: start_date is not set.
